{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulators.grid_world.grid_world import Maze\n",
    "from simulators.grid_world.metrics import compute_bad_steps\n",
    "\n",
    "grid_type = \"simple\"\n",
    "\n",
    "feature_type = \"one_hot\"\n",
    "dimensions = 124\n",
    "sigma = None\n",
    "\n",
    "# feature_type = \"simularity\"\n",
    "# dimensions = 100\n",
    "# sigma = 0.25\n",
    "\n",
    "n_tries_for_std = 10\n",
    "\n",
    "env = Maze(grid_type, feature_type, dimensions=dimensions, sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change reward to granular setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulators.grid_world.grid_world import set_granular_reward, set_normilized_reward, divide_reward_by\n",
    "\n",
    "env = set_granular_reward(env)\n",
    "env = set_normilized_reward(env)\n",
    "env = divide_reward_by(env, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try with logs and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad policy: 1\n"
     ]
    }
   ],
   "source": [
    "from algorithms.API.lstd import lstd_grid_word\n",
    "\n",
    "n_expert_samples = 200\n",
    "n_rl_samples = 0\n",
    "regularisor = 0.1\n",
    "regularisor_bellmann = 0.1\n",
    "max_iteration = 2\n",
    "epsilon_decay_limit = 0.9\n",
    "regularisor_expert = 0  # make LSPI\n",
    "# expert_loss_name = \"penalizer\"\n",
    "# expert_penality = 0.15\n",
    "expert_loss_name = None\n",
    "expert_penality = None\n",
    "\n",
    "show_args = {\"show_policy\":True, \"show_value_function\": False, \"show_statistics\": False}\n",
    "\n",
    "lspi_Q, lspi_policy = lstd_grid_word(\n",
    "    env,\n",
    "    n_expert_samples,\n",
    "    n_rl_samples,\n",
    "    regularisor,\n",
    "    regularisor_bellmann,\n",
    "    max_iteration,\n",
    "    epsilon_decay_limit,\n",
    "    regularisor_expert,\n",
    "    expert_loss_name,\n",
    "    expert_penality,\n",
    "    **show_args\n",
    ")\n",
    "print(\"Number of bad policy:\", compute_bad_steps(env, lspi_policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute real algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad policies: 10.9 +- 2.587\n",
      "Average time 0.337 +- 0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm \n",
    "from algorithms.API.lstd import lstd_grid_word\n",
    "\n",
    "n_expert_samples = 20\n",
    "n_rl_samples = 100\n",
    "regularisor = 0.1\n",
    "regularisor_bellmann = 0.1\n",
    "max_iteration = 10\n",
    "epsilon_decay_limit = 0\n",
    "regularisor_expert = 0  # make LSPI\n",
    "# expert_loss_name = \"large_margin\"\n",
    "# expert_loss_name = \"penalizer\"\n",
    "# expert_penality = 0.15\n",
    "expert_loss_name = None\n",
    "expert_penality = None\n",
    "\n",
    "show_args = {\"show_policy\":False, \"show_value_function\": False, \"show_statistics\": False}\n",
    "\n",
    "time_algorithm = []\n",
    "bad_policies = []\n",
    "\n",
    "for n_try in tqdm(range(n_tries_for_std)):\n",
    "    time_begin = time.time()\n",
    "    lspi_Q, lspi_policy = lstd_grid_word(\n",
    "        env,\n",
    "        n_expert_samples,\n",
    "        n_rl_samples,\n",
    "        regularisor,\n",
    "        regularisor_bellmann,\n",
    "        max_iteration,\n",
    "        epsilon_decay_limit,\n",
    "        regularisor_expert,\n",
    "        expert_loss_name,\n",
    "        expert_penality,\n",
    "        **show_args\n",
    "    )\n",
    "    time_algorithm.append(time.time() - time_begin)\n",
    "    bad_policies.append(compute_bad_steps(env, lspi_policy))\n",
    "\n",
    "print(f\"Bad policies: {np.around(np.mean(bad_policies), 3)} +- {np.around(np.std(bad_policies), 3)}\")\n",
    "print(f\"Average time {np.around(np.mean(time_algorithm), 3)} +- {np.around(np.std(time_algorithm), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the penalizer loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.011810341763857351\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.013287669165788095\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.019411982492751972\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.017770177036523775\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.022607899422010195\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.02177803089659469\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.013435105620568245\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.012588368445185166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:29<04:21, 29.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.018550248244137924\n",
      "10\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.016454957256068842\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.015483323888172496\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.026711045754247917\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.016046261698917135\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.014601935268881507\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.014023621677131268\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.0157181227413839\n",
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.014187337133463353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:53<03:28, 26.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! Warning ! Stopped before convergence\n",
      "Grad norm 0.020193924028927616\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:54<03:36, 27.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27409/3941378368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_try\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tries_for_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtime_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     lspi_Q, lspi_policy = lstd_grid_word(\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mn_expert_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/ReinforcementLearningWithDemonstration/algorithms/API/lstd.py\u001b[0m in \u001b[0;36mlstd_grid_word\u001b[0;34m(env, n_expert_samples, n_rl_samples, regularisor, regularisor_bellmann, max_iteration, epsilon_decay_limit, regularisor_expert, expert_loss_name, expert_penality, show_policy, show_value_function, show_statistics)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimise_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_bellman\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularisor_bellmann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimise_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_bellman\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_expert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/ReinforcementLearningWithDemonstration/algorithms/API/optimizers.py\u001b[0m in \u001b[0;36moptimise_w\u001b[0;34m(loss_w, w, samples_bellman, samples_expert, u, learning_rate)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-6\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgrad_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_expert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/ReinforcementLearningWithDemonstration/algorithms/API/losses.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self, w, samples_expert, u)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_expert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mgrad_bellman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_T_features\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mgrad_expert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm \n",
    "from algorithms.API.lstd import lstd_grid_word\n",
    "\n",
    "n_expert_samples = 20\n",
    "n_rl_samples = 100\n",
    "regularisor = 0.1\n",
    "regularisor_bellmann = 0.1\n",
    "max_iteration = 10\n",
    "epsilon_decay_limit = 0\n",
    "regularisor_expert = 0.1\n",
    "expert_loss_name = \"penalizer\"\n",
    "expert_penality = 0.01\n",
    "# expert_loss_name = None\n",
    "# expert_penality = None\n",
    "\n",
    "show_args = {\"show_policy\":False, \"show_value_function\": False, \"show_statistics\": False}\n",
    "\n",
    "time_algorithm = []\n",
    "bad_policies = []\n",
    "\n",
    "for n_try in tqdm(range(n_tries_for_std)):\n",
    "    time_begin = time.time()\n",
    "    lspi_Q, lspi_policy = lstd_grid_word(\n",
    "        env,\n",
    "        n_expert_samples,\n",
    "        n_rl_samples,\n",
    "        regularisor,\n",
    "        regularisor_bellmann,\n",
    "        max_iteration,\n",
    "        epsilon_decay_limit,\n",
    "        regularisor_expert,\n",
    "        expert_loss_name,\n",
    "        expert_penality,\n",
    "        **show_args\n",
    "    )\n",
    "    time_algorithm.append(time.time() - time_begin)\n",
    "    bad_policy = compute_bad_steps(env, lspi_policy)\n",
    "    print(bad_policy)\n",
    "    bad_policies.append(bad_policy)\n",
    "\n",
    "print(f\"Bad policies: {np.around(np.mean(bad_policies), 3)} +- {np.around(np.std(bad_policies), 3)}\")\n",
    "print(f\"Average time {np.around(np.mean(time_algorithm), 3)} +- {np.around(np.std(time_algorithm), 3)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f758ad8e5e9cb73d1ab62c182866944e1d4dbba00f99109599dd23e4b5a5cd7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('env_container': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
