{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from simulators.grid_world.grid_world import SimpleGridWorld, simulate_policy\n",
    "from simulators.grid_world import GAMMA, HORIZON\n",
    "\n",
    "simple_env = SimpleGridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from algorithms.VI_dynamic_programming import value_iteration\n",
    "\n",
    "Q_expert, expert_policy = value_iteration(simple_env.P, simple_env.R, GAMMA)\n",
    "\n",
    "# Uncomment if you want to simulate the policy\n",
    "# simulate_policy(expert_policy, \"../../videos/simple_grid_world/expert.mp4\", simple_env, HORIZON)\n",
    "\n",
    "V_expert = Q_expert.max(axis=1)\n",
    "img = simple_env.get_layout_img(V_expert)    \n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, env, epsilon_decay, gamma, regularisor_bellmann):\n",
    "        self.env = env\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.gamma = gamma\n",
    "        self.regularisor_bellmann = regularisor_bellmann\n",
    "\n",
    "        self.size_feature = env.get_feature(0, 0).shape[0]\n",
    "\n",
    "        self.buffer = []\n",
    "\n",
    "        self.A = None  # Grad matrix\n",
    "        self.b = None  # Grad matrix\n",
    "\n",
    "    def collect_samples(self, n_samples, w, trajectory):\n",
    "        state = self.env.initial_state_distribution\n",
    "\n",
    "        self.env.reset()\n",
    "        terminal = False\n",
    "\n",
    "        for idx_sample in range(n_samples):\n",
    "            if not trajectory:\n",
    "                state = np.random.choice(self.env._states)\n",
    "\n",
    "                while self.env.is_terminal(state):\n",
    "                    state = np.random.choice(self.env._states)\n",
    "\n",
    "                self.env.state = state\n",
    "            elif terminal:  # Trajectory case\n",
    "                self.env.reset()\n",
    "\n",
    "            # Policy improvement\n",
    "            if np.random.random() < self.epsilon_decay(len(self.buffer)):\n",
    "                action = np.random.choice(self.env._actions)\n",
    "            else:\n",
    "                action = np.argmax([self.env.get_feature(state, action) @ w for action in self.env._actions])\n",
    "\n",
    "            next_state, reward, terminal, _ = self.env.step(action)\n",
    "            next_action = np.argmax([self.env.get_feature(next_state, action) @ w for action in self.env._actions])\n",
    "\n",
    "            self.buffer.append((state, action, reward, next_state, next_action))\n",
    "            state = next_state\n",
    "\n",
    "    def compute_grad_matrices(self):\n",
    "        features = np.zeros((len(self.buffer), self.size_feature))\n",
    "        next_features = np.zeros((len(self.buffer), self.size_feature))\n",
    "        rewards = np.zeros(len(self.buffer))\n",
    "\n",
    "        for idx_sample, (state, action, reward, next_state, next_action) in enumerate(self.buffer):\n",
    "            features[idx_sample] = self.env.get_feature(state, action)\n",
    "            next_features[idx_sample] = self.env.get_feature(next_state, next_action)\n",
    "            rewards[idx_sample] = reward\n",
    "\n",
    "        inverse_matrix = np.linalg.inv(\n",
    "            features.T @ features + self.regularisor_bellmann * len(self.buffer) * np.eye(self.size_feature)\n",
    "        )\n",
    "\n",
    "        self.A = np.eye(self.size_feature) - self.gamma * inverse_matrix @ features.T @ next_features\n",
    "        self.b = inverse_matrix @ features.T @ rewards\n",
    "\n",
    "\n",
    "def lstd(env, n_samples_per_iteration, regularisor, regularisor_bellmann, trajectory=False, max_iteration=10, tol=1e-1):\n",
    "    from algorithms.epsilon_greedy import epsilon_decay\n",
    "    from simulators.grid_world import GAMMA\n",
    "\n",
    "    replay_buffer = ReplayBuffer(env, epsilon_decay, GAMMA, regularisor_bellmann)\n",
    "\n",
    "    w = np.random.random(replay_buffer.size_feature)\n",
    "\n",
    "    for iteration in range(max_iteration):\n",
    "        # Exploration\n",
    "        replay_buffer.collect_samples(n_samples_per_iteration, w, trajectory)\n",
    "        replay_buffer.compute_grad_matrices()\n",
    "\n",
    "        # Evaluation\n",
    "        grad = float(\"inf\") * np.ones(w.shape)\n",
    "\n",
    "        while np.linalg.norm(grad) < tol:\n",
    "            grad = np.zeros(w.shape)\n",
    "\n",
    "            for sample in replay_buffer.buffer:\n",
    "                feature = env.get_feature(sample[0])\n",
    "                grad += feature.T @ (replay_buffer.A @ w + replay_buffer.b) @ replay_buffer.A.T @ feature\n",
    "\n",
    "            grad = grad / len(replay_buffer.buffer) + regularisor * w\n",
    "\n",
    "            w -= regularisor * grad\n",
    "\n",
    "        # Improvement\n",
    "        # Done when samples are collected.\n",
    "\n",
    "    Q = np.zeros((env.S, env.A))\n",
    "\n",
    "    for state in env._states:\n",
    "        for action in env._actions:\n",
    "            Q[state, action] = env.get_feature(state, action) @ w\n",
    "\n",
    "    return Q, np.argmax(Q, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from algorithms.LSTD import lstd\n",
    "\n",
    "n_samples_per_iteration = 100\n",
    "regularisor = 0.1\n",
    "regularisor_bellmann = 0.1\n",
    "max_iteration = 10\n",
    "trajectory = False\n",
    "\n",
    "Q_lstd, lstd_policy = lstd(simple_env, n_samples_per_iteration, regularisor, regularisor_bellmann, trajectory=trajectory, max_iteration=max_iteration, tol=1e-5)\n",
    "\n",
    "# Uncomment if you want to simulate the policy\n",
    "# simulate_policy(lstd_policy, \"../../videos/simple_grid_world/lstd.mp4\", simple_env, HORIZON)\n",
    "\n",
    "V_lstd = Q_lstd.max(axis=1)\n",
    "img = simple_env.get_layout_img(V_lstd)    \n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f758ad8e5e9cb73d1ab62c182866944e1d4dbba00f99109599dd23e4b5a5cd7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('env_container': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
